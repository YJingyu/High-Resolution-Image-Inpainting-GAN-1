---

num_workers: 16

train_parameters:
  num_epoch: 40
  lr_g: 0.0001 # Adam learning rate
  lr_d: 0.0004 # Adam learning rate
  batch_size: 4
  lambda_perceptual: 100 # the parameter of FML1Loss (perceptual loss)
  mask_type: free_form # 'single_bbox' or 'bbox'
  image_size: 512
  weight_decay: 0
  lr_decrease_epoch: 10 # lr decrease at certain epoch and its multiple
  lr_decrease_factor: 0.5 # lr decrease factor, for classification default 0.1
  lambda_l1: 256 # the parameter of L1Loss


save_path: "./models"
sample_path: "./samples"
gan_type: "WGAN"
checkpoint_interval: 1 # interval between model checkpoints
load_name_g: "" # load model name
load_name_d: "" # load model name

latent_channels: 32 # latent channels
pad_type: replicate # the padding type
activation: elu
norm1: none
norm: none
init_type: kaiming
init_gain: 0.2

baseroot: "./dataset/data_large" # the training folder: val_256, test_large, data_256
